#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
é‡æ–°æ ¼å¼åŒ–äº§å“åˆ†ææŠ¥å‘Š

æ­¤è„šæœ¬è¯»å–ç°æœ‰çš„äº§å“åˆ†æ Markdown æ–‡ä»¶ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šçš„æ¨¡æ¿é‡æ–°æ ¼å¼åŒ–å®ƒä»¬ã€‚
"""

import os
import re
import glob
import argparse
import traceback
from datetime import datetime

# è¿™äº›æ¨¡æ¿å·²ç»å†…ç½®åœ¨ä»£ç ä¸­ï¼Œä¸å†éœ€è¦å•ç‹¬å®šä¹‰

def extract_product_info(content):
    """ä»ç°æœ‰å†…å®¹ä¸­æå–äº§å“ä¿¡æ¯"""
    info = {}

    # æå–äº§å“åç§°
    name_match = re.search(r'^# (.+?)$', content, re.MULTILINE)
    if name_match:
        info['name'] = name_match.group(1).strip()

    # å°è¯•æå–å…¶ä»–ä¿¡æ¯
    patterns = {
        'rank': r'æ’å:\s*(.+?)$',
        'revenue': r'æ”¶å…¥:\s*(.+?)$',
        'product_link': r'äº§å“é“¾æ¥:\s*(.+?)$',
        'analysis_link': r'åˆ†æé“¾æ¥:\s*(.+?)$',
        'monthly_visits': r'æœˆè®¿é—®é‡:\s*(.+?)$',
        'company': r'å…¬å¸:\s*(.+?)$',
        'founded_date': r'æˆç«‹æ—¥æœŸ:\s*(.+?)$',
        'pricing': r'å®šä»·:\s*(.+?)$',
        'platform': r'å¹³å°:\s*(.+?)$',
        'core_features': r'æ ¸å¿ƒåŠŸèƒ½:\s*(.+?)$',
        'use_cases': r'åº”ç”¨åœºæ™¯:\s*(.+?)$',
        'analysis_time': r'åˆ†ææ—¶é—´:\s*(.+?)$',
        'analysis_tool': r'åˆ†æå·¥å…·:\s*(.+?)$'
    }

    for key, pattern in patterns.items():
        match = re.search(pattern, content, re.MULTILINE)
        if match:
            info[key] = match.group(1).strip()

    return info

def extract_analysis_content(content):
    """ä»ç°æœ‰å†…å®¹ä¸­æå–åˆ†æå†…å®¹"""
    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ‰€æœ‰æå–çš„å†…å®¹
    extracted = {}

    # æå–äº§å“åˆ†ææ¡†æ¶éƒ¨åˆ†
    framework_match = re.search(r'## äº§å“åˆ†ææ¡†æ¶åº”ç”¨\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if framework_match:
        extracted['framework'] = framework_match.group(1).strip()
    else:
        # å°è¯•æå–å…¶ä»–åˆ†æå†…å®¹
        analysis_match = re.search(r'## äº§å“åˆ†æ\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
        if analysis_match:
            extracted['framework'] = analysis_match.group(1).strip()
        else:
            extracted['framework'] = ""

    # æå–SWOTåˆ†æ
    swot_match = re.search(r'## SWOTåˆ†æ\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if swot_match:
        extracted['swot'] = swot_match.group(1).strip()
    else:
        extracted['swot'] = ""

    # æå–è¯„åˆ†ä½“ç³»
    score_match = re.search(r'## è¯„åˆ†ä½“ç³».*?\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if score_match:
        extracted['score'] = score_match.group(1).strip()
    else:
        extracted['score'] = ""

    # æå–å…³é”®æ´å¯Ÿä¸å»ºè®®
    insights_match = re.search(r'## å…³é”®æ´å¯Ÿä¸å»ºè®®\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if insights_match:
        extracted['insights'] = insights_match.group(1).strip()
    else:
        extracted['insights'] = ""

    # æå–æ€»ç»“éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
    summary_match = re.search(r'## æ€»ç»“\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if summary_match:
        extracted['summary'] = summary_match.group(1).strip()
    else:
        extracted['summary'] = ""

    # æå–äº§å“æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
    description_match = re.search(r'## äº§å“æè¿°\s*\n(.*?)(?=##|\Z)', content, re.DOTALL)
    if description_match:
        extracted['description'] = description_match.group(1).strip()
    else:
        extracted['description'] = ""

    return extracted

def reformat_markdown(file_path):
    """é‡æ–°æ ¼å¼åŒ– Markdown æ–‡ä»¶"""
    try:
        # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–äº§å“ä¿¡æ¯
        product_info = extract_product_info(content)

        # æå–åˆ†æå†…å®¹
        analysis_content = extract_analysis_content(content)

        # æ„å»ºæ–°çš„ Markdown å†…å®¹
        new_content = f"# {product_info.get('name', 'Unknown Product')}\n\n"

        # æ·»åŠ äº§å“ä¿¡æ¯éƒ¨åˆ†
        new_content += "## äº§å“ä¿¡æ¯\n\n"
        new_content += f"ğŸ“Š æ’å: {product_info.get('rank', '')}\n\n"
        new_content += f"ğŸ’° æ”¶å…¥: {product_info.get('revenue', '')}\n\n"
        new_content += f"ğŸ”— äº§å“é“¾æ¥: {product_info.get('product_link', '')}\n\n"
        new_content += f"ğŸ” åˆ†æé“¾æ¥: {product_info.get('analysis_link', '')}\n\n"
        new_content += f"ğŸ‘€ æœˆè®¿é—®é‡: {product_info.get('monthly_visits', '')}\n\n"
        new_content += f"ğŸ¢ å…¬å¸: {product_info.get('company', '')}\n\n"
        new_content += f"ğŸ—“ï¸ æˆç«‹æ—¥æœŸ: {product_info.get('founded_date', '')}\n\n"
        new_content += f"ğŸ’² å®šä»·: {product_info.get('pricing', '')}\n\n"
        new_content += f"ğŸ“± å¹³å°: {product_info.get('platform', '')}\n\n"
        new_content += f"ğŸ”§ æ ¸å¿ƒåŠŸèƒ½: {product_info.get('core_features', '')}\n\n"
        new_content += f"ğŸŒ åº”ç”¨åœºæ™¯: {product_info.get('use_cases', '')}\n\n"
        new_content += f"â±ï¸ åˆ†ææ—¶é—´: {product_info.get('analysis_time', datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥'))}\n\n"
        new_content += f"ğŸ¤– åˆ†æå·¥å…·: {product_info.get('analysis_tool', 'DeepSeek AI')}\n\n"

        # æ·»åŠ äº§å“åˆ†ææ¡†æ¶éƒ¨åˆ†
        new_content += "## äº§å“åˆ†ææ¡†æ¶\n\n"

        # ä»åŸå§‹å†…å®¹ä¸­æå–å„ä¸ªéƒ¨åˆ†
        framework = analysis_content.get('framework', '')

        # å°è¯•ä»åˆ†æå†…å®¹ä¸­æå–é—®é¢˜ç­”æ¡ˆ
        problem_match = re.search(r'è§£å†³ä»€ä¹ˆé—®é¢˜.*?(?:-|\n\n)', framework, re.DOTALL)
        problem = problem_match.group(0).strip() if problem_match else ""
        new_content += f"ğŸ’¡ è¿™ä¸ªäº§å“è§£å†³çš„æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Ÿ\n{problem}\n\n"

        users_match = re.search(r'ç›®æ ‡ç”¨æˆ·.*?(?:-|\n\n)', framework, re.DOTALL)
        users = users_match.group(0).strip() if users_match else ""
        new_content += f"ğŸ‘¤ ç”¨æˆ·æ˜¯è°ï¼Ÿ\n{users}\n\n"

        needs_match = re.search(r'ç”¨æˆ·éœ€æ±‚.*?(?:-|\n\n)', framework, re.DOTALL)
        needs = needs_match.group(0).strip() if needs_match else ""
        new_content += f"ğŸ¤” ç”¨æˆ·ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ\n{needs}\n\n"

        reviews_match = re.search(r'ç”¨æˆ·è¯„ä»·.*?(?:-|\n\n)', framework, re.DOTALL)
        reviews = reviews_match.group(0).strip() if reviews_match else ""
        new_content += f"ğŸ—£ï¸ ç”¨æˆ·æ˜¯å¦‚ä½•è¯„ä»·å®ƒçš„ï¼Ÿ\n{reviews}\n\n"

        acquisition_match = re.search(r'ç”¨æˆ·è·å–.*?(?:-|\n\n)', framework, re.DOTALL)
        acquisition = acquisition_match.group(0).strip() if acquisition_match else ""
        new_content += f"ğŸ” å®ƒæ˜¯å¦‚ä½•æ‰¾åˆ°ç”¨æˆ·çš„ï¼Ÿ\n{acquisition}\n\n"

        business_match = re.search(r'å•†ä¸šæ¨¡å¼.*?(?:-|\n\n)', framework, re.DOTALL)
        business = business_match.group(0).strip() if business_match else ""
        new_content += f"ğŸ’° å®ƒèµšé’±å—ï¼Ÿå¤šå°‘ï¼Ÿ\n{business}\n\n"

        insights_match = re.search(r'äº§å“æ´å¯Ÿ.*?(?:-|\n\n)', framework, re.DOTALL)
        insights = insights_match.group(0).strip() if insights_match else ""
        new_content += f"ğŸ§  æˆ‘ä»è¿™ä¸ªäº§å“èº«ä¸Šå­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ\n{insights}\n\n"

        challenges_match = re.search(r'å®ç°æŒ‘æˆ˜.*?(?:-|\n\n)', framework, re.DOTALL)
        challenges = challenges_match.group(0).strip() if challenges_match else ""
        new_content += f"ğŸ¤” å®ƒçš„ä»€ä¹ˆåšæ³•ä¸å®¹æ˜“ï¼Ÿ\n{challenges}\n\n"

        pitch_match = re.search(r'ä¸€å¥è¯æ¨é”€.*?(?:-|\n\n)', framework, re.DOTALL)
        pitch = pitch_match.group(0).strip() if pitch_match else ""
        new_content += f"ğŸ¤— ä¸€å¥è¯æ¨é”€ï¼š\n{pitch}\n\n"

        diff_match = re.search(r'å·®å¼‚åŒ–æ–¹æ³•.*?(?:-|\n\n)', framework, re.DOTALL)
        diff = diff_match.group(0).strip() if diff_match else ""
        new_content += f"ğŸ’¡ ä¸åŒçš„æ–¹æ³•ï¼š\n{diff}\n\n"

        feasibility_match = re.search(r'å¯è¡Œæ€§åˆ†æ.*?(?:-|\n\n)', framework, re.DOTALL)
        feasibility = feasibility_match.group(0).strip() if feasibility_match else ""
        new_content += f"ğŸ‰ æˆ‘èƒ½åšå‡ºæ¥å—ï¼Ÿ\n{feasibility}\n\n"

        strategy_match = re.search(r'è·å®¢ç­–ç•¥.*?(?:-|\n\n)', framework, re.DOTALL)
        strategy = strategy_match.group(0).strip() if strategy_match else ""
        new_content += f"ğŸ§­ å¦‚ä½•æ‰¾åˆ°ç”¨æˆ·ï¼Ÿ\n{strategy}\n\n"

        team_match = re.search(r'å›¢é˜Ÿä¼˜åŠ¿.*?(?:-|\n\n)', framework, re.DOTALL)
        team = team_match.group(0).strip() if team_match else ""
        new_content += f"ğŸ¤” ä¸ºä»€ä¹ˆæ˜¯æˆ‘ï¼Ÿ\n{team}\n\n"

        persistence_match = re.search(r'æŒç»­æ€§è¯„ä¼°.*?(?:-|\n\n)', framework, re.DOTALL)
        persistence = persistence_match.group(0).strip() if persistence_match else ""
        new_content += f"â¤ï¸ æˆ‘èƒ½åšæŒå—ï¼Ÿ\n{persistence}\n\n"

        # æ·»åŠ å…¶ä»–éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        if analysis_content.get('swot', ''):
            new_content += f"## SWOTåˆ†æ\n\n{analysis_content['swot']}\n\n"

        if analysis_content.get('score', ''):
            new_content += f"## è¯„åˆ†ä½“ç³»\n\n{analysis_content['score']}\n\n"

        if analysis_content.get('insights', ''):
            new_content += f"## å…³é”®æ´å¯Ÿä¸å»ºè®®\n\n{analysis_content['insights']}\n\n"

        if analysis_content.get('summary', ''):
            new_content += f"## æ€»ç»“\n\n{analysis_content['summary']}\n\n"

        # ç›´æ¥è¦†ç›–åŸå§‹æ–‡ä»¶
        output_path = file_path

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        print(f"å·²é‡æ–°æ ¼å¼åŒ–: {output_path}")
        return output_path

    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡æ–°æ ¼å¼åŒ–äº§å“åˆ†ææŠ¥å‘Š")
    parser.add_argument('-i', '--input', dest='input_path', required=True,
                        help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('-r', '--recursive', dest='recursive',
                        action='store_true',
                        help='é€’å½’å¤„ç†å­ç›®å½•')

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_path):
        print(f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input_path}")
        return

    # å¤„ç†å•ä¸ªæ–‡ä»¶
    if os.path.isfile(args.input_path):
        if args.input_path.endswith('.md'):
            reformat_markdown(args.input_path)
        else:
            print(f"è·³è¿‡é Markdown æ–‡ä»¶: {args.input_path}")

    # å¤„ç†ç›®å½•
    elif os.path.isdir(args.input_path):
        # ç¡®å®šæœç´¢æ¨¡å¼
        if args.recursive:
            search_pattern = os.path.join(args.input_path, '**', '*.md')
            md_files = glob.glob(search_pattern, recursive=True)
        else:
            search_pattern = os.path.join(args.input_path, '*.md')
            md_files = glob.glob(search_pattern)

        # å¤„ç†æ‰¾åˆ°çš„æ‰€æœ‰ Markdown æ–‡ä»¶
        if md_files:
            print(f"æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
            for file_path in md_files:
                reformat_markdown(file_path)
        else:
            print(f"åœ¨ {args.input_path} ä¸­æœªæ‰¾åˆ° Markdown æ–‡ä»¶")

if __name__ == "__main__":
    main()
