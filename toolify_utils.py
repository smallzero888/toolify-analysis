#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Toolify AIåˆ†æå·¥å…·é›† - å·¥å…·æ¨¡å—
æä¾›å…±äº«çš„åŠŸèƒ½å‡½æ•°å’Œç±»ï¼Œå‡å°‘ä»£ç é‡å¤ï¼Œæé«˜ä»£ç å†…èšæ€§
"""

import os
import time
import pandas as pd
import numpy as np
from datetime import datetime
import re
import json
from typing import List, Dict, Any, Union, Tuple, Optional
import sys
import glob
import logging
import traceback
from openpyxl.utils import get_column_letter
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("toolify_utils")

# å°è¯•åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸ python-dotenvæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½.envæ–‡ä»¶")

# TensorFlowå’ŒGPUç›¸å…³
TF_AVAILABLE = False
GPU_AVAILABLE = False

# å°è¯•å¯¼å…¥TensorFlowå¹¶æ£€æŸ¥GPU
try:
    import tensorflow as tf

    # è®¾ç½®TensorFlowæ—¥å¿—çº§åˆ«
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0=INFO, 1=WARNING, 2=ERROR, 3=FATAL
    tf.get_logger().setLevel('ERROR')

    # è®¾ç½®å†…å­˜å¢é•¿
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        for device in physical_devices:
            tf.config.experimental.set_memory_growth(device, True)

    # æ ‡è®°TensorFlowå¯ç”¨
    TF_AVAILABLE = True

    # æ£€æŸ¥GPUå¯ç”¨æ€§
    try:
        def get_available_gpus():
            """è·å–å¯ç”¨çš„GPUè®¾å¤‡åˆ—è¡¨"""
            try:
                from tensorflow.python.client import device_lib
                local_device_protos = device_lib.list_local_devices()
                # ä½¿ç”¨æ›´é€šç”¨çš„æ–¹å¼è®¿é—®è®¾å¤‡å±æ€§
                gpu_devices = []
                for device in local_device_protos:
                    if hasattr(device, 'device_type') and getattr(device, 'device_type') == 'GPU':
                        # ä½¿ç”¨getattrå®‰å…¨åœ°è·å–nameå±æ€§
                        device_name = getattr(device, 'name', str(device))
                        gpu_devices.append(device_name)
                return gpu_devices
            except ImportError:
                logger.warning("âš ï¸ æ— æ³•å¯¼å…¥device_libæ¨¡å—ï¼ŒGPUæ£€æµ‹å°†ä¸å¯ç”¨")
                return []

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
        gpus = get_available_gpus()
        GPU_AVAILABLE = len(gpus) > 0

        if GPU_AVAILABLE:
            logger.info(f"âœ… TensorFlowå·²åŠ è½½ï¼Œå‘ç°{len(gpus)}ä¸ªGPUè®¾å¤‡")
            for i, gpu in enumerate(gpus):
                logger.info(f"  GPU #{i+1}: {gpu}")
        else:
            logger.info("âœ… TensorFlowå·²åŠ è½½ï¼Œä½†æœªå‘ç°GPUè®¾å¤‡")
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥GPUå¯ç”¨æ€§æ—¶å‡ºé”™: {str(e)}")
        GPU_AVAILABLE = False

except ImportError:
    logger.warning("âš ï¸ æœªæ‰¾åˆ°TensorFlowï¼ŒæŸäº›åŠŸèƒ½å°†ä¸å¯ç”¨")
    TF_AVAILABLE = False
    GPU_AVAILABLE = False
except Exception as e:
    logger.error(f"âŒ åˆå§‹åŒ–TensorFlowæ—¶å‡ºé”™: {str(e)}")
    logger.debug(traceback.format_exc())
    TF_AVAILABLE = False
    GPU_AVAILABLE = False

# åŠ è½½åˆ†ææ¡†æ¶
def load_analysis_framework():
    """ä»æ–‡ä»¶åŠ è½½åˆ†ææ¡†æ¶"""
    try:
        framework_file = "analysis_framework.txt"
        if os.path.exists(framework_file):
            with open(framework_file, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°åˆ†ææ¡†æ¶æ–‡ä»¶ {framework_file}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¡†æ¶")
            return """
## äº§å“åˆ†ææ¡†æ¶

ğŸ’¡ è¿™ä¸ªäº§å“è§£å†³çš„æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Ÿ

ğŸ‘¤ ç”¨æˆ·æ˜¯è°ï¼Ÿ

ğŸ¤” ç”¨æˆ·ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ

ğŸ—£ï¸ ç”¨æˆ·æ˜¯å¦‚ä½•è¯„ä»·å®ƒçš„ï¼Ÿ

ğŸ” å®ƒæ˜¯å¦‚ä½•æ‰¾åˆ°ç”¨æˆ·çš„ï¼Ÿ

ğŸ’° å®ƒèµšé’±å—ï¼Ÿå¤šå°‘ï¼Ÿ

ğŸ§  æˆ‘ä»è¿™ä¸ªäº§å“èº«ä¸Šå­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ

ğŸ¤” å®ƒçš„ä»€ä¹ˆåšæ³•ä¸å®¹æ˜“ï¼Ÿ

ğŸ¤— ä¸€å¥è¯æ¨é”€ï¼š

ğŸ’¡ ä¸åŒçš„æ–¹æ³•ï¼š

ğŸ‰ æˆ‘èƒ½åšå‡ºæ¥å—ï¼Ÿ

ğŸ§­ å¦‚ä½•æ‰¾åˆ°ç”¨æˆ·ï¼Ÿ

ğŸ¤” ä¸ºä»€ä¹ˆæ˜¯æˆ‘ï¼Ÿ

â¤ï¸ æˆ‘èƒ½åšæŒå—ï¼Ÿ
"""
    except Exception as e:
        print(f"âŒ åŠ è½½åˆ†ææ¡†æ¶æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¡†æ¶")
        return """## äº§å“åˆ†ææ¡†æ¶\n\nğŸ’¡ è¿™ä¸ªäº§å“è§£å†³çš„æ˜¯ä»€ä¹ˆé—®é¢˜ï¼Ÿ\n\nğŸ‘¤ ç”¨æˆ·æ˜¯è°ï¼Ÿ\n\n..."""

# åŠ è½½Markdownæ¨¡æ¿
def load_markdown_template():
    """ä»æ–‡ä»¶åŠ è½½Markdownæ¨¡æ¿"""
    # ä¸å†å°è¯•åŠ è½½å¤–éƒ¨æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤æ¨¡æ¿
    default_template = """# {name}

## äº§å“ä¿¡æ¯

- ğŸ“Š æ’å: {rank}
- ğŸ’° æ”¶å…¥: {revenue}
- ğŸ”— é“¾æ¥: [{website}]({url})
- ğŸ‘€ æœˆè®¿é—®é‡: {monthly_visits}

## äº§å“æè¿°

{description}

## åˆ†æ

{analysis}

## è¯„åˆ†å¡

| è¯„ä¼°ç»´åº¦ | å¾—åˆ†(1-10) |
|---------|-----------|
| åˆ›æ–°æ€§   | {innovation_score} |
| å•†ä¸šæ¨¡å¼å¯è¡Œæ€§ | {business_model_score} |
| å¸‚åœºå¢é•¿æ½œåŠ› | {growth_potential_score} |
| æ€»åˆ† | {total_score} |

## SWOTåˆ†æ

| ä¼˜åŠ¿ (Strengths) | åŠ£åŠ¿ (Weaknesses) |
|-----------------|------------------|
| {strengths} | {weaknesses} |

| æœºä¼š (Opportunities) | å¨èƒ (Threats) |
|---------------------|--------------|
| {opportunities} | {threats} |
"""
    print(f"[INFO] ä½¿ç”¨é»˜è®¤Markdownæ¨¡æ¿")
    return default_template

# æå–å…³é”®ç‚¹
def extract_key_points(analysis):
    """ä»åˆ†ææ–‡æœ¬ä¸­æå–å…³é”®ç‚¹"""
    # ä¸å†éœ€è¦ä»»ä½•å…³é”®ç‚¹ï¼Œè¿”å›ç©ºå­—å…¸
    return {}

# Excelå¤„ç†å‡½æ•°
def format_excel_output(df, output_file):
    """æ”¹è¿›Excelè¾“å‡ºæ ¼å¼ï¼Œä½¿å…¶æ›´æ˜“äºé˜…è¯»"""
    try:
        # é¦–å…ˆå°è¯•ä½¿ç”¨åŸºæœ¬æ¨¡å¼ä¿å­˜ï¼Œç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶
        basic_output = output_file.replace('.xlsx', '_basic.xlsx')
        df.fillna('').to_excel(basic_output, index=False)
        print(f"âœ… å·²ä¿å­˜åŸºæœ¬Excelæ–‡ä»¶: {basic_output}")

        # å°è¯•ä½¿ç”¨xlsxwriterå¼•æ“ä»¥æ”¯æŒæ ¼å¼è®¾ç½®
        try:
            # ä½¿ç”¨xlsxwriterå¼•æ“ä»¥æ”¯æŒæ ¼å¼è®¾ç½®
            writer = pd.ExcelWriter(output_file, engine='xlsxwriter')
            df.to_excel(writer, index=False, sheet_name='äº§å“åˆ†æ')

            # è·å–xlsxwriterå¯¹è±¡
            workbook = writer.book
            worksheet = writer.sheets['äº§å“åˆ†æ']

            # è®¾ç½®åˆ—å®½
            col_widths = {
                'A': 10,  # æ’å
                'B': 25,  # å·¥å…·åç§°
                'C': 30,  # å·¥å…·é“¾æ¥
                'D': 25,  # ç½‘ç«™
                'E': 15,  # æ”¯ä»˜å¹³å°
                'F': 15,  # æœˆè®¿é—®é‡
                'G': 40,  # æè¿°
                'H': 15,  # æ”¶å…¥
                'I': 80   # å®Œæ•´åˆ†æ
            }

            # å®‰å…¨åœ°è®¾ç½®åˆ—å®½
            for col, width in col_widths.items():
                try:
                    worksheet.set_column(f'{col}:{col}', width)
                except:
                    pass

            # å®‰å…¨åœ°å…³é—­writer
            try:
                writer.close()
                print(f"âœ… å·²ä¿å­˜æ ¼å¼ä¼˜åŒ–çš„Excelæ–‡ä»¶: {output_file}")
                return True
            except Exception as close_error:
                print(f"âš ï¸ å…³é—­Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(close_error)}")
                return True  # ä»ç„¶è¿”å›æˆåŠŸï¼Œå› ä¸ºåŸºæœ¬æ–‡ä»¶å·²ä¿å­˜

        except Exception as format_error:
            print(f"âš ï¸ ä½¿ç”¨xlsxwriteræ ¼å¼åŒ–Excelæ—¶å‡ºé”™: {str(format_error)}")
            return True  # ä»ç„¶è¿”å›æˆåŠŸï¼Œå› ä¸ºåŸºæœ¬æ–‡ä»¶å·²ä¿å­˜

    except Exception as e:
        print(f"âŒ ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return False

# æ¸…ç†URLå‡½æ•°
def clean_url(url):
    """
    æ¸…ç†URLï¼Œç§»é™¤åè®®å‰ç¼€å’Œç»“å°¾çš„æ–œæ 

    Args:
        url (str): å¾…æ¸…ç†çš„URL

    Returns:
        str: æ¸…ç†åçš„URL
    """
    if url is None:
        return ""

    # ç¡®ä¿URLæ˜¯å­—ç¬¦ä¸²ç±»å‹
    if not isinstance(url, str):
        try:
            url = str(url)
        except:
            return ""

    url = url.strip()

    # ç§»é™¤HTTP/HTTPSåè®®
    if url.startswith("http://"):
        url = url[7:]
    elif url.startswith("https://"):
        url = url[8:]

    # ç§»é™¤æœ«å°¾çš„æ–œæ 
    while url.endswith("/"):
        url = url[:-1]

    return url

# ä»URLæå–åŸŸå
def extract_domain(url):
    """
    ä»URLä¸­æå–åŸŸå

    Args:
        url (str): è¾“å…¥URL

    Returns:
        str: æå–çš„åŸŸå
    """
    if not url:
        return ""

    # ç¡®ä¿URLæ˜¯å­—ç¬¦ä¸²ç±»å‹
    if not isinstance(url, str):
        try:
            url = str(url)
        except:
            return ""

    # æ¸…ç†URL
    url = clean_url(url)

    # æå–åŸŸå
    if not url:
        return ""

    parts = url.split("/")
    if not parts:
        return ""

    domain = parts[0]

    # ç§»é™¤www.å‰ç¼€
    if domain.startswith("www."):
        domain = domain[4:]

    return domain

# æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
def find_latest_files(directory: str, pattern: str = "Toolify_AI_Revenue_*.xlsx") -> Dict[str, str]:
    """
    æŸ¥æ‰¾ç›®å½•ä¸­åŒ¹é…ç»™å®šæ¨¡å¼çš„æœ€æ–°æ–‡ä»¶

    Args:
        directory (str): è¦æœç´¢çš„ç›®å½•
        pattern (str): æ–‡ä»¶åæ¨¡å¼

    Returns:
        dict: åŒ…å«æœ€æ–°æ–‡ä»¶çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {"cn": "path/to/file.xlsx", "en": "path/to/file.xlsx"}
    """
    if not os.path.exists(directory) or not os.path.isdir(directory):
        logger.warning(f"ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {directory}")
        return {}

    # è·å–æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
    # åœ¨å¤šä¸ªå¯èƒ½çš„ä½ç½®æŸ¥æ‰¾æ–‡ä»¶
    search_dirs = [
        directory,  # åŸå§‹ç›®å½•
        os.path.join(directory, "toolify_data"),  # toolify_dataå­ç›®å½•
        os.path.join("output", "toolify_data")  # æ ‡å‡†ç›®å½•
    ]

    files = []
    for search_dir in search_dirs:
        if os.path.exists(search_dir) and os.path.isdir(search_dir):
            logger.info(f"åœ¨ {search_dir} ä¸­æŸ¥æ‰¾æ–‡ä»¶...")
            found_files = glob.glob(os.path.join(search_dir, pattern))
            if found_files:
                files.extend(found_files)
                logger.info(f"åœ¨ {search_dir} ä¸­æ‰¾åˆ° {len(found_files)} ä¸ªæ–‡ä»¶")

    if not files:
        logger.warning(f"åœ¨{directory}ä¸­æœªæ‰¾åˆ°åŒ¹é…{pattern}çš„æ–‡ä»¶")
        return {}

    # æŒ‰è¯­è¨€åˆ†ç±»æ–‡ä»¶
    cn_files = [f for f in files if "_CN_" in f.upper()]
    en_files = [f for f in files if "_EN_" in f.upper()]

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    cn_files.sort(key=os.path.getmtime, reverse=True)
    en_files.sort(key=os.path.getmtime, reverse=True)

    result = {}

    # è·å–æœ€æ–°çš„CNæ–‡ä»¶
    if cn_files:
        result["cn"] = cn_files[0]
        logger.info(f"æ‰¾åˆ°æœ€æ–°çš„CNæ–‡ä»¶: {cn_files[0]}")

    # è·å–æœ€æ–°çš„ENæ–‡ä»¶
    if en_files:
        result["en"] = en_files[0]
        logger.info(f"æ‰¾åˆ°æœ€æ–°çš„ENæ–‡ä»¶: {en_files[0]}")

    return result

def markdown_to_plaintext(markdown_content):
    """
    å°†Markdownæ ¼å¼çš„æ–‡æœ¬è½¬æ¢ä¸ºé€‚åˆExcelå•å…ƒæ ¼çš„çº¯æ–‡æœ¬æ ¼å¼

    Args:
        markdown_content (str): Markdownæ ¼å¼çš„æ–‡æœ¬å†…å®¹

    Returns:
        str: è½¬æ¢åçš„çº¯æ–‡æœ¬å†…å®¹
    """
    if not markdown_content:
        return ""

    # æ›¿æ¢æ‰€æœ‰è¡¨æ ¼ç›¸å…³ç¬¦å·
    text = re.sub(r'\|', ' | ', markdown_content)

    # æ›¿æ¢æ ‡é¢˜æ ¼å¼ï¼ˆ# æ ‡é¢˜ï¼‰
    text = re.sub(r'^\s*#{1,6}\s+(.+)$', r'\1', text, flags=re.MULTILINE)

    # æ›¿æ¢åŠ ç²—å’Œæ–œä½“æ ¼å¼
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)  # åŠ ç²—
    text = re.sub(r'__(.+?)__', r'\1', text)      # åŠ ç²—
    text = re.sub(r'\*(.+?)\*', r'\1', text)      # æ–œä½“
    text = re.sub(r'_(.+?)_', r'\1', text)        # æ–œä½“

    # æ›¿æ¢åˆ—è¡¨æ ¼å¼ï¼ˆ- å’Œ * å¼€å¤´çš„é¡¹ï¼‰
    text = re.sub(r'^\s*[-*]\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)

    # æ›¿æ¢é“¾æ¥æ ¼å¼ [æ–‡æœ¬](é“¾æ¥)
    text = re.sub(r'\[(.+?)\]\((.+?)\)', r'\1 (\2)', text)

    # æ›¿æ¢å›¾ç‰‡æ ¼å¼ ![alt](é“¾æ¥)
    text = re.sub(r'!\[(.+?)\]\((.+?)\)', r'[å›¾ç‰‡: \1]', text)

    # ç§»é™¤æ°´å¹³çº¿
    text = re.sub(r'^\s*[-*_]{3,}\s*$', '', text, flags=re.MULTILINE)

    # ç§»é™¤è¡¨æ ¼æ ¼å¼ç¬¦å·ï¼ˆ| --- | ç±»çš„è¡Œï¼‰
    text = re.sub(r'^\s*\|[-:\s|]+\|\s*$', '', text, flags=re.MULTILINE)

    # æ›¿æ¢å¤šä¸ªè¿ç»­ç©ºè¡Œä¸ºå•ä¸ªç©ºè¡Œ
    text = re.sub(r'\n{3,}', '\n\n', text)

    return text

# æ›´æ–°Excelä¸­çš„åˆ†æç»“æœ
def update_excel_with_analysis(excel_file, analysis_results, markdown_dir="output/toolify_analysis/markdown_files"):
    """æ›´æ–°Excelæ–‡ä»¶ï¼Œç§»é™¤äº§å“åˆ†æåˆ—ï¼Œåªä¿ç•™å®Œæ•´åˆ†æ"""
    try:
        df = pd.read_excel(excel_file)

        # ç¡®ä¿ç§»é™¤äº§å“åˆ†æåˆ—
        if "äº§å“åˆ†æ" in df.columns:
            df = df.drop(columns=["äº§å“åˆ†æ"])

        # åªä¿ç•™å®Œæ•´åˆ†æåˆ—
        if "å®Œæ•´åˆ†æ" not in df.columns:
            df["å®Œæ•´åˆ†æ"] = ""

        # æ›´æ–°åˆ†æç»“æœ
        total_results = len(analysis_results)
        print(f"\nå¼€å§‹æ›´æ–°Excelæ–‡ä»¶ [å…±{total_results}ä¸ªäº§å“]")

        # å®šä¹‰è¿›åº¦æ¡é¢œè‰²å’Œç¬¦å·
        bar_length = 40
        filled_char = "â–ˆ"  # å®å¿ƒæ–¹å—
        empty_char = "â–‘"   # ç©ºå¿ƒæ–¹å—

        for i, result in enumerate(analysis_results):
            # è®¡ç®—è¿›åº¦
            progress = (i + 1) / total_results
            filled_length = int(bar_length * progress)

            # æ¸…é™¤å½“å‰è¡Œå¹¶æ˜¾ç¤ºæ–°è¿›åº¦æ¡
            if i > 0:  # ä¸æ˜¯ç¬¬ä¸€ä¸ªå…ƒç´ 
                print("\r", end="")

            # æ‰“å°è¿›åº¦æ¡
            progress_bar = filled_char * filled_length + empty_char * (bar_length - filled_length)
            print(f"\rè¿›åº¦: {progress_bar} {progress:.1%} ({i+1}/{total_results})", end="")

            product = result["product"]
            tool_name = product.get("Tool Name", "") or product.get("å·¥å…·åç§°", "")

            # æŸ¥æ‰¾å¯¹åº”çš„è¡Œ
            mask = None
            if "Tool Name" in df.columns and tool_name:
                mask = df["Tool Name"] == tool_name
            elif "å·¥å…·åç§°" in df.columns and tool_name:
                mask = df["å·¥å…·åç§°"] == tool_name

            if mask is None or not mask.any():
                continue

            # è·å–åˆ†æå·¥å…·ä¿¡æ¯
            api_name = result.get("api_name", "DeepSeek AI")  # é»˜è®¤ä½¿ç”¨DeepSeek AI

            # æ›´æ–°å®Œæ•´åˆ†æåˆ—
            if result["markdown_path"] and os.path.exists(result["markdown_path"]):
                try:
                    with open(result["markdown_path"], 'r', encoding='utf-8') as md_file:
                        markdown_content = md_file.read()

                        # æ›´æ–°åˆ†æå·¥å…·ä¿¡æ¯
                        if "ğŸ¤– åˆ†æå·¥å…·: " in markdown_content:
                            markdown_content = re.sub(
                                r'ğŸ¤– åˆ†æå·¥å…·: [^\n]+',
                                f'ğŸ¤– åˆ†æå·¥å…·: {api_name}',
                                markdown_content
                            )
                        elif "ğŸ¤– Analysis Tool: " in markdown_content:
                            markdown_content = re.sub(
                                r'ğŸ¤– Analysis Tool: [^\n]+',
                                f'ğŸ¤– Analysis Tool: {api_name}',
                                markdown_content
                            )

                        # è½¬æ¢ä¸ºçº¯æ–‡æœ¬å¹¶æ›´æ–°Excel
                        plain_text = markdown_to_plaintext(markdown_content)
                        df.loc[mask, "å®Œæ•´åˆ†æ"] = plain_text

                        # å°†æ›´æ–°åçš„å†…å®¹å†™å›æ–‡ä»¶
                        with open(result["markdown_path"], 'w', encoding='utf-8') as md_out:
                            md_out.write(markdown_content)
                except Exception as md_error:
                    print(f"\nâš ï¸ è¯»å–markdownæ–‡ä»¶å¤±è´¥: {str(md_error)}")

        # å®Œæˆåæ‰“å°å®Œæˆä¿¡æ¯
        print(f"\rè¿›åº¦: {filled_char * bar_length} 100.0% ({total_results}/{total_results}) âœ… å®Œæˆ!\n")

        # ç¡®å®šè¾“å‡ºç›®å½•
        # ä½¿ç”¨markdown_dirçš„çˆ¶ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
        if markdown_dir:
            # å¦‚æœæ˜¯ç±»ä¼¼ "output\toolify_analysis_20250419\cn\markdown_files" çš„è·¯å¾„
            # åˆ™è¾“å‡ºç›®å½•åº”ä¸º "output\toolify_analysis_20250419"
            parts = os.path.normpath(markdown_dir).split(os.sep)
            if len(parts) >= 3 and parts[0] == "output" and parts[1].startswith("toolify_analysis"):
                # ä½¿ç”¨å‰ä¸¤éƒ¨åˆ†ä½œä¸ºè¾“å‡ºç›®å½•
                output_dir = os.path.join(parts[0], parts[1])
            else:
                # å¦‚æœä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œåˆ™ä½¿ç”¨çˆ¶ç›®å½•
                output_dir = os.path.dirname(markdown_dir)
        else:
            # é»˜è®¤è¾“å‡ºç›®å½•
            output_dir = "output/toolify_analysis"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        file_name = os.path.basename(excel_file)
        base_name, ext = os.path.splitext(file_name)
        output_file = os.path.join(output_dir, f"{base_name}_analyzed{ext}")

        # ä¿å­˜Excelæ–‡ä»¶
        format_excel_with_beauty(df, output_file)

        print(f"âœ… å·²å°†åˆ†æç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶: {output_file}")
        return output_file

    except Exception as e:
        print(f"âŒ æ›´æ–°Excelæ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def format_excel_with_beauty(df, output_file):
    """ç”¨ç¾è§‚çš„æ ¼å¼ä¿å­˜Excelæ–‡ä»¶"""
    try:
        # åˆ›å»ºExcelå†™å…¥å™¨
        writer = pd.ExcelWriter(output_file, engine='openpyxl')

        # å†™å…¥æ•°æ®
        df.to_excel(writer, index=False, sheet_name='Sheet1')

        # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨
        workbook = writer.book
        worksheet = writer.sheets['Sheet1']

        # åº”ç”¨æ ¼å¼ï¼ˆä½¿ç”¨openpyxlçš„æ ·å¼ï¼‰
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side

        # è®¾ç½®åˆ—å®½
        for idx, col in enumerate(df.columns):
            column_letter = get_column_letter(idx + 1)
            # æ ‡å‡†åˆ—å®½
            col_width = 15

            # ç‰¹å®šåˆ—å®½åº¦è°ƒæ•´
            if col in ["äº§å“åˆ†æ", "å®Œæ•´åˆ†æ"]:
                col_width = 50  # åˆ†æåˆ—å®½ä¸€äº›
            elif col in ["æ”¶å…¥", "Revenue", "å¹´æ”¶å…¥", "Annual Revenue"]:
                col_width = 12

            worksheet.column_dimensions[column_letter].width = col_width

        # è®¾ç½®æ ‡é¢˜è¡Œæ ¼å¼
        header_font = Font(bold=True, size=12, color="FFFFFF")
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)

        # åº”ç”¨æ ‡é¢˜è¡Œæ ¼å¼
        for col_num, column_title in enumerate(df.columns, 1):
            cell = worksheet.cell(row=1, column=col_num)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment

        # è®¾ç½®å•å…ƒæ ¼è¾¹æ¡†
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )

        # åº”ç”¨åˆ°æ‰€æœ‰å•å…ƒæ ¼
        for row in range(1, len(df) + 2):  # +2 å› ä¸ºæœ‰æ ‡é¢˜è¡Œå’Œç´¢å¼•ä»1å¼€å§‹
            for col_num in range(1, len(df.columns) + 1):
                cell = worksheet.cell(row=row, column=col_num)
                cell.border = thin_border

                # å†…å®¹å•å…ƒæ ¼æ ¼å¼
                if row > 1:
                    cell.alignment = Alignment(vertical='top', wrap_text=True)

                    # ç‰¹æ®Šåˆ—æ ¼å¼
                    column_name = df.columns[col_num-1]
                    if column_name in ["äº§å“åˆ†æ", "å®Œæ•´åˆ†æ"]:
                        cell.alignment = Alignment(vertical='top', wrap_text=True)

        # ä¿å­˜æ–‡ä»¶
        writer.close()
        print(f"âœ… Excelæ–‡ä»¶å·²ä¿å­˜: {output_file}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜Excelæ ¼å¼åŒ–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

# å¸¸é‡
ANALYSIS_FRAMEWORK = load_analysis_framework()
MARKDOWN_TEMPLATE = load_markdown_template()

def get_datetime_str(format="%Y%m%d"):
    """
    è·å–æ ¼å¼åŒ–çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²

    Args:
        format (str): æ—¥æœŸæ—¶é—´æ ¼å¼

    Returns:
        str: æ ¼å¼åŒ–çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
    """
    return datetime.now().strftime(format)

def format_number(number):
    """
    æ ¼å¼åŒ–æ•°å­—ï¼Œæ·»åŠ åƒä½åˆ†éš”ç¬¦

    Args:
        number: è¦æ ¼å¼åŒ–çš„æ•°å­—

    Returns:
        str: æ ¼å¼åŒ–åçš„æ•°å­—å­—ç¬¦ä¸²
    """
    if number is None:
        return "N/A"

    try:
        return f"{int(number):,}"
    except (ValueError, TypeError):
        try:
            return f"{float(number):,.2f}"
        except (ValueError, TypeError):
            return str(number)

def convert_size(size_bytes):
    """
    å°†å­—èŠ‚è½¬æ¢ä¸ºäººç±»å¯è¯»çš„å¤§å°

    Args:
        size_bytes (int): å­—èŠ‚å¤§å°

    Returns:
        str: äººç±»å¯è¯»çš„å¤§å°å­—ç¬¦ä¸²
    """
    if size_bytes == 0:
        return "0B"

    size_name = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0

    while size_bytes >= 1024 and i < len(size_name) - 1:
        size_bytes /= 1024
        i += 1

    return f"{size_bytes:.2f} {size_name[i]}"

def parse_monthly_visits(visits_str):
    """
    è§£ææœˆè®¿é—®é‡å­—ç¬¦ä¸²ä¸ºæ•°å€¼

    Args:
        visits_str (str): è®¿é—®é‡å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "1.2M" æˆ– "500K"

    Returns:
        float: æ•°å€¼å½¢å¼çš„è®¿é—®é‡
    """
    if not visits_str or visits_str == "N/A":
        return 0.0

    # ç§»é™¤æ‰€æœ‰ç©ºæ ¼å’Œé€—å·
    visits_str = visits_str.strip().replace(" ", "").replace(",", "")

    # æå–æ•°å­—å’Œå•ä½
    match = re.match(r"^([\d.]+)([KMB])?$", visits_str.upper())

    if not match:
        try:
            return float(visits_str)
        except (ValueError, TypeError):
            return 0.0

    value, unit = match.groups()
    factor = 1

    # æ ¹æ®å•ä½è°ƒæ•´æ•°å€¼
    if unit == "K":
        factor = 1000
    elif unit == "M":
        factor = 1000000
    elif unit == "B":
        factor = 1000000000

    try:
        return float(value) * factor
    except (ValueError, TypeError):
        return 0.0

# å¯åœ¨æ­¤å¤„æ·»åŠ æ›´å¤šå·¥å…·å‡½æ•°

def clean_number(value: str) -> Optional[float]:
    """
    æ¸…ç†å¹¶è½¬æ¢å­—ç¬¦ä¸²æ•°å­—ä¸ºæµ®ç‚¹æ•°

    Args:
        value: è¦è½¬æ¢çš„å­—ç¬¦ä¸²å€¼ï¼Œå¯èƒ½åŒ…å«é€—å·ã€è´§å¸ç¬¦å·ç­‰

    Returns:
        æ¸…ç†åçš„æµ®ç‚¹æ•°å€¼ï¼Œå¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å›None
    """
    if not value or not isinstance(value, str):
        return None

    # ç§»é™¤å¸¸è§éæ•°å­—å­—ç¬¦
    for char in ['$', 'Â¥', 'â‚¬', ',', ' ', '+']:
        value = value.replace(char, '')

    # å¤„ç†k/m/bç®€å†™
    multipliers = {
        'k': 1000,
        'm': 1000000,
        'b': 1000000000
    }

    value = value.lower().strip()
    for suffix, multiplier in multipliers.items():
        if value.endswith(suffix):
            try:
                return float(value[:-1]) * multiplier
            except ValueError:
                return None

    # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    try:
        return float(value)
    except ValueError:
        return None

def format_filename(base_name: str, date_str: Optional[str] = None, extension: str = 'xlsx') -> str:
    """
    æ ¼å¼åŒ–æ–‡ä»¶åï¼Œæ·»åŠ æ—¥æœŸåç¼€

    Args:
        base_name: åŸºæœ¬æ–‡ä»¶å
        date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
        extension: æ–‡ä»¶æ‰©å±•åï¼Œé»˜è®¤ä¸ºxlsx

    Returns:
        æ ¼å¼åŒ–åçš„æ–‡ä»¶å
    """
    if not date_str:
        date_str = datetime.now().strftime("%Y%m%d")

    # ç¡®ä¿æ‰©å±•åæ ¼å¼æ­£ç¡®
    ext = extension.lstrip('.')

    return f"{base_name}_{date_str}.{ext}"

def ensure_dir(directory: str) -> None:
    """
    ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º

    Args:
        directory: è¦ç¡®ä¿å­˜åœ¨çš„ç›®å½•è·¯å¾„
    """
    if not os.path.exists(directory):
        os.makedirs(directory)
        logger.info(f"åˆ›å»ºç›®å½•: {directory}")

def get_display_path(file_path: str, max_length: int = 60) -> str:
    """
    è·å–ç”¨äºæ˜¾ç¤ºçš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤ªé•¿åˆ™æˆªæ–­

    Args:
        file_path: å®Œæ•´æ–‡ä»¶è·¯å¾„
        max_length: æœ€å¤§æ˜¾ç¤ºé•¿åº¦

    Returns:
        é€‚åˆæ˜¾ç¤ºçš„æ–‡ä»¶è·¯å¾„
    """
    if not file_path:
        return "[æ— è·¯å¾„]"

    if len(file_path) <= max_length:
        return file_path

    # ä¿ç•™æ–‡ä»¶åå’Œéƒ¨åˆ†è·¯å¾„
    file_name = os.path.basename(file_path)
    dir_part = os.path.dirname(file_path)

    available_length = max_length - len(file_name) - 4  # 4 for ".../"

    if available_length <= 0:
        # æ–‡ä»¶åå·²ç»å¤ªé•¿ï¼Œåªæ˜¾ç¤ºéƒ¨åˆ†æ–‡ä»¶å
        return f"...{file_name[-(max_length-3):]}"

    # æ˜¾ç¤ºéƒ¨åˆ†ç›®å½•å’Œå®Œæ•´æ–‡ä»¶å
    return f"...{dir_part[-available_length:]}/{file_name}"
