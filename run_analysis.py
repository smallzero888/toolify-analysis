#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è¿è¡Œæ•°æ®é‡‡é›†å’Œåˆ†æçš„è„šæœ¬

æ­¤è„šæœ¬æ‰§è¡Œä»¥ä¸‹æ“ä½œ:
1. è¿è¡Œtoolify_scraper.pyçˆ¬å–æ•°æ®ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰
2. è¿è¡Œanalyze_data_with_gpuè¿›è¡Œæ•°æ®åˆ†æ
3. è¿è¡Œproduct_analyzer.pyè¿›è¡Œäº§å“åˆ†æï¼ˆå¯é€‰ï¼‰
4. æ”¯æŒåˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“ï¼ˆé›†æˆè‡ªanalyze_ranks.pyï¼‰

ä½¿ç”¨:
    # åŸºæœ¬ç”¨æ³•
    python run_analysis.py [--scraping] [--analysis] [--analyze-products]

    # åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“
    python run_analysis.py --rank-range 1-5 --language cn  # åˆ†ææ’å1-5çš„ä¸­æ–‡äº§å“
    python run_analysis.py --rank-range 6-10 --language en  # åˆ†ææ’å6-10çš„è‹±æ–‡äº§å“

æ³¨æ„:
    æœ¬è„šæœ¬å·²é›†æˆanalyze_ranks.pyçš„åŠŸèƒ½ï¼Œä¸å†éœ€è¦å•ç‹¬è¿è¡Œè¯¥è„šæœ¬ã€‚
"""

import os
import sys
import argparse
import subprocess
import traceback
import time
import re
import glob
from datetime import datetime

# æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ¨¡å—
try:
    import pandas as pd
    import numpy as np
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„æ¨¡å—: {e}")
    print("è¯·å…ˆè¿è¡Œ: pip install pandas numpy")
    sys.exit(1)

# å¯¼å…¥å·¥å…·æ¨¡å—
try:
    from toolify_utils import (
        TF_AVAILABLE,
        GPU_AVAILABLE,
        find_latest_files
    )

    # å¯¼å…¥çˆ¬è™«æ¨¡å—çš„å‡½æ•°
    from toolify_scraper import scrape_toolify_ranking, main as scrape_main
    print("âœ… å·²æˆåŠŸå¯¼å…¥å·¥å…·æ¨¡å—")
except ImportError as e:
    print(f"é”™è¯¯: æ— æ³•å¯¼å…¥å·¥å…·æ¨¡å—: {e}")
    traceback.print_exc()
    sys.exit(1)


def run_scraping(output_dir="output/toolify_data", languages=None):
    """
    è¿è¡Œç½‘ç«™çˆ¬è™«è·å–æ•°æ®

    Args:
        output_dir (str): è¾“å‡ºç›®å½•
        languages (list): è¦çˆ¬å–çš„è¯­è¨€åˆ—è¡¨ï¼Œä¾‹å¦‚ ["cn", "en"]

    Returns:
        dict: åŒ…å«çˆ¬å–ç»“æœçš„å­—å…¸
    """
    if languages is None:
        languages = ["cn", "en"]

    results = {}
    date_str = datetime.now().strftime("%Y%m%d")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    for lang in languages:
        try:
            print(f"\nğŸ” å¼€å§‹çˆ¬å– {lang.upper()} æ•°æ®...")

            # è®¾ç½®è¾“å‡ºç›®å½•
            date_str = datetime.now().strftime("%Y%m%d")
            output_dir_with_date = os.path.join(output_dir, f"toolify_analysis_{date_str}")
            os.makedirs(output_dir_with_date, exist_ok=True)

            # ä¸ºä¸åŒè¯­è¨€è®¾ç½®ä¸åŒçš„URL
            if lang.lower() == "cn":
                url = "https://www.toolify.ai/zh/Best-AI-Tools-revenue"
            else:  # en
                url = "https://www.toolify.ai/Best-AI-Tools-revenue"

            # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
            output_file = os.path.join(output_dir_with_date, f"Toolify_AI_Revenue_{lang.upper()}_{date_str}.xlsx")

            # çˆ¬å–æ•°æ®
            data = scrape_toolify_ranking(url, output_file, language=lang if lang == "cn" else "en")

            if data:
                rows_count = len(data)
                print(f"âœ… å·²æˆåŠŸçˆ¬å– {rows_count} æ¡{lang.upper()}æ•°æ®å¹¶ä¿å­˜åˆ° {output_file}")
                results[lang] = {
                    "count": rows_count,
                    "file": output_file,
                    "data": data
                }
            else:
                print(f"âš ï¸ çˆ¬å–{lang.upper()}æ•°æ®å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®")

        except Exception as e:
            print(f"âŒ çˆ¬å–{lang.upper()}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()

    return results


# å®šä¹‰åŸºæœ¬çš„æ•°æ®åˆ†æåŠŸèƒ½
def analyze_data_with_gpu(cn_data=None, en_data=None, cn_file=None, en_file=None, output_dir="output/toolify_analysis", date_str=None):
    """
    ä½¿ç”¨GPUåŠ é€Ÿåˆ†ææ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰

    Args:
        cn_data (list, optional): ä¸­æ–‡æ•°æ®åˆ—è¡¨
        en_data (list, optional): è‹±æ–‡æ•°æ®åˆ—è¡¨
        cn_file (str, optional): ä¸­æ–‡æ•°æ®æ–‡ä»¶è·¯å¾„
        en_file (str, optional): è‹±æ–‡æ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir (str): è¾“å‡ºç›®å½•
        date_str (str, optional): æ—¥æœŸå­—ç¬¦ä¸²

    Returns:
        dict: åˆ†æç»“æœ
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    print(f"ğŸ” å¼€å§‹æ•°æ®åˆ†æï¼Œä½¿ç”¨GPU: {GPU_AVAILABLE}")

    # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ä½†æ²¡æœ‰æ•°æ®ï¼Œå°è¯•åŠ è½½æ•°æ®
    if not cn_data and cn_file and os.path.exists(cn_file):
        try:
            cn_data = pd.read_excel(cn_file).to_dict('records')
            print(f"âœ… ä»æ–‡ä»¶åŠ è½½ä¸­æ–‡æ•°æ®: {cn_file}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–ä¸­æ–‡æ•°æ®æ–‡ä»¶: {str(e)}")

    if not en_data and en_file and os.path.exists(en_file):
        try:
            en_data = pd.read_excel(en_file).to_dict('records')
            print(f"âœ… ä»æ–‡ä»¶åŠ è½½è‹±æ–‡æ•°æ®: {en_file}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–è‹±æ–‡æ•°æ®æ–‡ä»¶: {str(e)}")

    # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ•°æ®é›†
    if not cn_data and not en_data:
        print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # åˆ†æé€»è¾‘
    try:
        # åˆå¹¶ä¸­è‹±æ–‡æ•°æ®
        all_data = []
        if cn_data:
            all_data.extend(cn_data)
        if en_data:
            all_data.extend(en_data)

        # æå–å¹¶æ¸…ç†æœˆè®¿é—®é‡æ•°æ®
        monthly_visits = []
        for item in all_data:
            visit_str = item.get("Monthly Visits") or item.get("æœˆè®¿é—®é‡", "0")
            try:
                # ç§»é™¤éæ•°å­—å­—ç¬¦
                visit_str = visit_str.replace(",", "").replace("K", "000").replace("M", "000000")
                visits = float(visit_str)
                monthly_visits.append(visits)
            except (ValueError, AttributeError):
                monthly_visits.append(0)

        # ä½¿ç”¨NumPyè¿›è¡ŒåŸºæœ¬ç»Ÿè®¡åˆ†æ
        stats = {
            "count": len(monthly_visits),
            "sum": np.sum(monthly_visits),
            "mean": np.mean(monthly_visits),
            "median": np.median(monthly_visits),
            "std": np.std(monthly_visits),
            "min": np.min(monthly_visits),
            "max": np.max(monthly_visits)
        }

        # åˆ›å»ºåˆ†æè¾“å‡ºæ–‡ä»¶
        os.makedirs(output_dir, exist_ok=True)
        summary_file = os.path.join(output_dir, f"Traffic_Summary_{date_str}.xlsx")

        # å°†åˆ†æç»“æœä¿å­˜ä¸ºDataFrame
        stats_df = pd.DataFrame([stats])
        stats_df.to_excel(summary_file, index=False)

        print(f"âœ… åˆ†æå®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š: {summary_file}")
        return {
            "stats": stats,
            "summary_file": summary_file
        }

    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æå‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None


def run_analysis(scraping_results=None, output_dir="output/toolify_analysis", date_str=None):
    """
    è¿è¡Œæ•°æ®åˆ†æ

    Args:
        scraping_results (dict): çˆ¬è™«ç»“æœ
        output_dir (str): è¾“å‡ºç›®å½•
        date_str (str): æ—¥æœŸå­—ç¬¦ä¸²

    Returns:
        dict: åˆ†æç»“æœ
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    # å¦‚æœæ²¡æœ‰æä¾›çˆ¬è™«ç»“æœï¼Œå°è¯•æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶
    if not scraping_results:
        print("\nğŸ” å¯»æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶...")

        try:
            latest_files = find_latest_files(output_dir, "Toolify_AI_Revenue_*.xlsx")

            if not latest_files:
                print(f"âš ï¸ åœ¨{output_dir}ç›®å½•ä¸­æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
                return None

            # é‡å»ºç»“æœç»“æ„
            scraping_results = {}
            for lang, file_path in latest_files.items():
                if os.path.exists(file_path):
                    try:
                        data = pd.read_excel(file_path).to_dict('records')
                        scraping_results[lang] = {
                            "count": len(data),
                            "file": file_path,
                            "data": data
                        }
                        print(f"âœ… å·²åŠ è½½{lang.upper()}æ•°æ®: {file_path}")
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•è¯»å–{file_path}: {str(e)}")
                else:
                    print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        except Exception as e:
            print(f"âŒ æŸ¥æ‰¾æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

    # è¿è¡Œåˆ†æ
    print("\nğŸ” å¼€å§‹åˆ†ææ•°æ®...")

    try:
        # æå–æ•°æ®å’Œæ–‡ä»¶è·¯å¾„
        cn_data = scraping_results.get("cn", {}).get("data")
        en_data = scraping_results.get("en", {}).get("data")
        cn_file = scraping_results.get("cn", {}).get("file")
        en_file = scraping_results.get("en", {}).get("file")

        if not cn_data and not en_data and not cn_file and not en_file:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯åˆ†æçš„æ•°æ®")
            return None

        # è¿è¡ŒGPUåŠ é€Ÿåˆ†æ
        analysis_result = analyze_data_with_gpu(
            cn_data=cn_data,
            en_data=en_data,
            cn_file=cn_file,
            en_file=en_file,
            output_dir=output_dir,
            date_str=date_str
        )

        return analysis_result

    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†ææ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None


def run_product_analyzer(data_files, output_dir="output/toolify_analysis", batch_size=5, use_gpu=False, count=None):
    """
    è¿è¡Œäº§å“åˆ†æ

    Args:
        data_files (dict): æ•°æ®æ–‡ä»¶å­—å…¸ï¼Œæ ¼å¼ä¸º {"cn": "path/to/file.xlsx", "en": "path/to/file.xlsx"}
        output_dir (str): è¾“å‡ºç›®å½•
        batch_size (int): æ‰¹å¤„ç†å¤§å°
        use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPU
        count (int, optional): è¦åˆ†æçš„äº§å“æ•°é‡

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    # éªŒè¯è¾“å…¥
    if not data_files:
        print("âš ï¸ æœªæä¾›æ•°æ®æ–‡ä»¶")
        return False

    # æŸ¥æ‰¾product_analyzer.py
    script_path = "product_analyzer.py"
    if not os.path.exists(script_path):
        print(f"âŒ æœªæ‰¾åˆ°äº§å“åˆ†æè„šæœ¬: {script_path}")
        return False

    success = True

    for lang, file_path in data_files.items():
        if not os.path.exists(file_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        try:
            print(f"\nğŸ” å¼€å§‹åˆ†æ {lang.upper()} äº§å“æ•°æ®: {file_path}")

            # æ„å»ºå‘½ä»¤
            cmd = [
                sys.executable,
                script_path,
                "-i", file_path,
                "-o", f"{output_dir}/{lang}",
                "-b", str(batch_size),
                "-l", lang
            ]

            # æ·»åŠ äº§å“æ•°é‡å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
            if count is not None:
                cmd.extend(["-c", str(count)])

            # æ·»åŠ GPUæ ‡å¿—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if use_gpu and GPU_AVAILABLE:
                cmd.append("--gpu")

            # è¿è¡Œå‘½ä»¤
            print(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

            # å®æ—¶è¾“å‡º
            while True:
                # æ·»åŠ å®‰å…¨æ£€æŸ¥é˜²æ­¢è®¿é—®None
                if process.stdout is None:
                    break

                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())

            # è·å–è¿”å›ç 
            return_code = process.poll()

            if return_code == 0:
                print(f"âœ… {lang.upper()}äº§å“åˆ†æå®Œæˆ")
            else:
                print(f"âŒ {lang.upper()}äº§å“åˆ†æå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
                success = False

                # æ‰“å°é”™è¯¯è¾“å‡º
                if process.stderr is not None:
                    stderr = process.stderr.read()
                    if stderr:
                        print(f"é”™è¯¯ä¿¡æ¯:\n{stderr}")

        except Exception as e:
            print(f"âŒ è¿è¡Œäº§å“åˆ†ææ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            success = False

    return success


# æ–°å¢: åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“å‡½æ•°
def analyze_specific_ranks(rank_range, language="cn", date_str=None, api="deepseek", use_gpu=False, update_excel=False, retry_count=3):
    """
    åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“

    Args:
        rank_range (str): æ’åèŒƒå›´ï¼Œå¦‚"1-5"
        language (str): è¯­è¨€ï¼Œ"cn"æˆ–"en"
        date_str (str, optional): æ—¥æœŸå­—ç¬¦ä¸²
        api (str): ä½¿ç”¨çš„APIï¼Œ"deepseek"æˆ–"openai"
        use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPU
        update_excel (bool): æ˜¯å¦å°†åˆ†æç»“æœæ’å…¥åˆ°Excelè¡¨æ ¼ä¸­
        retry_count (int): APIè°ƒç”¨å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    # æ£€æŸ¥æ’åèŒƒå›´æ ¼å¼
    if "-" not in rank_range:
        print("é”™è¯¯: æ’åèŒƒå›´æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºå¦‚'1-5'è¿™æ ·çš„æ ¼å¼")
        return False

    # è§£ææ’åèŒƒå›´
    try:
        start_rank, end_rank = map(int, rank_range.split("-"))
    except ValueError:
        print("é”™è¯¯: æ’åå¿…é¡»æ˜¯æ•°å­—")
        return False

    if start_rank <= 0 or end_rank <= 0:
        print("é”™è¯¯: æ’åå¿…é¡»å¤§äº0")
        return False

    if start_rank > end_rank:
        print("é”™è¯¯: èµ·å§‹æ’åä¸èƒ½å¤§äºç»“æŸæ’å")
        return False

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    data_dir = os.path.join("output", "toolify_data")
    input_file = os.path.join(data_dir, f"Toolify_AI_Revenue_{language.upper()}_{date_str}.xlsx")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_file}")
        print("è¯·ç¡®ä¿å·²ç»çˆ¬å–äº†æ¦œå•æ•°æ®")
        return False

    # è®¡ç®—å‚æ•°
    start_index = start_rank - 1  # è½¬æ¢ä¸ºåŸºäº0çš„ç´¢å¼•
    count = end_rank - start_rank + 1

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = os.path.join("output", f"toolify_analysis_{date_str}", language)

    # æ„å»ºå‘½ä»¤
    cmd = [
        "python", "product_analyzer.py",
        "-i", input_file,
        "-o", output_dir,
        "-s", str(start_index),
        "-c", str(count),
        "-l", language
    ]

    # æ·»åŠ APIå‚æ•°
    if api.lower() == "openai":
        cmd.extend(["--api", "openai"])

    # æ·»åŠ GPUæ ‡å¿—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_gpu and GPU_AVAILABLE:
        cmd.append("--gpu")

    # æ˜¾ç¤ºå³å°†æ‰§è¡Œçš„æ“ä½œ
    lang_display = "ä¸­æ–‡" if language == "cn" else "è‹±æ–‡"
    print(f"æ­£åœ¨åˆ†æ{lang_display}æ¦œå•ä¸­æ’å{start_rank}åˆ°{end_rank}çš„äº§å“...")

    # æ‰§è¡Œå‘½ä»¤
    success = False
    attempt = 0
    max_attempts = max(1, retry_count + 1)  # è‡³å°‘å°è¯•ä¸€æ¬¡

    while attempt < max_attempts and not success:
        attempt += 1
        try:
            print(f"\nå°è¯• {attempt}/{max_attempts}: æ­£åœ¨åˆ†æäº§å“...")
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                print(f"\nåˆ†æå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ° {output_dir} ç›®å½•ä¸‹ã€‚")
                success = True
            else:
                print(f"é”™è¯¯: åˆ†æè¿è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode})")
                print(f"é”™è¯¯è¾“å‡º: {result.stderr}")

                if attempt < max_attempts:
                    wait_time = 5 * attempt  # æ¯æ¬¡é‡è¯•ç­‰å¾…æ—¶é—´å¢åŠ 
                    print(f"å°†åœ¨ {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
        except Exception as e:
            print(f"é”™è¯¯: æ‰§è¡Œåˆ†ææ—¶å‡ºé”™: {str(e)}")

            if attempt < max_attempts:
                wait_time = 5 * attempt
                print(f"å°†åœ¨ {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

    # å¦‚æœæˆåŠŸå¹¶éœ€è¦æ›´æ–°Excelï¼Œåˆ™å°†MDå†…å®¹æ’å…¥åˆ°Excelè¡¨æ ¼ä¸­
    if success and update_excel:
        try:
            # è·å–æ‰€æœ‰åˆ†æç»“æœ
            markdown_dir = os.path.join(output_dir, "markdown_files")
            if not os.path.exists(markdown_dir):
                print(f"è­¦å‘Š: æ‰¾ä¸åˆ°Markdownæ–‡ä»¶ç›®å½•: {markdown_dir}")
                return success

            # è·å–æ‰€æœ‰åˆ†æç»“æœæ–‡ä»¶
            md_files = glob.glob(os.path.join(markdown_dir, "*.md"))
            if not md_files:
                print("è­¦å‘Š: æ‰¾ä¸åˆ°ä»»ä½•Markdownæ–‡ä»¶")
                return success

            print(f"\næ‰¾åˆ° {len(md_files)} ä¸ªåˆ†æç»“æœæ–‡ä»¶")

            # è¯»å–åŸå§‹æ•°æ®
            try:
                # è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶
                tools = pd.read_excel(input_file).to_dict('records')
                print(f"\nå·²åŠ è½½åŸå§‹æ•°æ®: {len(tools)} æ¡è®°å½•")
            except Exception as e:
                print(f"é”™è¯¯: æ— æ³•è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶: {str(e)}")
                return success

            # å‡†å¤‡åˆ†æç»“æœ
            analysis_results = []
            for md_file in md_files:
                # ä»æ–‡ä»¶åæå–æ’å
                file_name = os.path.basename(md_file)
                rank_match = re.match(r'^(\d+)-', file_name)
                if not rank_match:
                    continue

                rank = int(rank_match.group(1))

                # ä»åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°å¯¹åº”çš„äº§å“
                product = None
                for p in tools:
                    p_rank = p.get("Rank") or p.get("æ’å")
                    try:
                        p_rank = int(p_rank)
                    except (ValueError, TypeError):
                        continue

                    if p_rank == rank:
                        product = p
                        break

                if not product:
                    continue

                # æ·»åŠ åˆ°åˆ†æç»“æœåˆ—è¡¨
                analysis_results.append({
                    "product": product,
                    "markdown_path": md_file
                })

            if not analysis_results:
                print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœ")
                return success

            # æ›´æ–°Excelæ–‡ä»¶
            from toolify_utils import update_excel_with_analysis
            updated_file = update_excel_with_analysis(
                input_file,  # ä½¿ç”¨è¾“å…¥æ–‡ä»¶ä½œä¸ºè¦æ›´æ–°çš„Excelæ–‡ä»¶
                analysis_results,
                markdown_dir=markdown_dir
            )

            if updated_file:
                print(f"\næˆåŠŸæ›´æ–°Excelæ–‡ä»¶: {updated_file}")
            else:
                print("è­¦å‘Š: æ›´æ–°Excelæ–‡ä»¶å¤±è´¥")
        except Exception as e:
            print(f"é”™è¯¯: æ›´æ–°Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()

    return success


def insert_md_to_excel(excel_file=None, markdown_dir=None, date_str=None, language="cn"):
    """
    å°†Markdownæ–‡ä»¶å†…å®¹æ’å…¥åˆ°Excelè¡¨æ ¼ä¸­

    Args:
        excel_file (str, optional): Excelæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾
        markdown_dir (str, optional): Markdownæ–‡ä»¶ç›®å½•ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾
        date_str (str, optional): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
        language (str): è¯­è¨€ï¼Œ"cn"æˆ–"en"

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    # å¦‚æœæ²¡æœ‰æä¾›Excelæ–‡ä»¶è·¯å¾„ï¼Œå°è¯•æŸ¥æ‰¾
    if excel_file is None:
        data_dir = os.path.join("output", "toolify_data")
        excel_file = os.path.join(data_dir, f"Toolify_Top_AI_Revenue_Rankings_{language.upper()}_{date_str}.xlsx")

        if not os.path.exists(excel_file):
            # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
            alt_excel_file = os.path.join(data_dir, f"Toolify_AI_Revenue_{language.upper()}_{date_str}.xlsx")
            if os.path.exists(alt_excel_file):
                excel_file = alt_excel_file
            else:
                # å°è¯•æŸ¥æ‰¾ä»»ä½•åŒ¹é…çš„Excelæ–‡ä»¶
                excel_files = glob.glob(os.path.join(data_dir, f"*{language.upper()}*{date_str}*.xlsx"))
                if excel_files:
                    excel_file = excel_files[0]
                else:
                    print(f"é”™è¯¯: æ‰¾ä¸åˆ°Excelæ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š --excel-file å‚æ•°")
                    return False

    # å¦‚æœæ²¡æœ‰æä¾›Markdownç›®å½•ï¼Œå°è¯•æŸ¥æ‰¾
    if markdown_dir is None:
        markdown_dir = os.path.join("output", f"toolify_analysis_{date_str}", language, "markdown_files")
        if not os.path.exists(markdown_dir):
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°Markdownæ–‡ä»¶ç›®å½•: {markdown_dir}")
            print("è¯·æ‰‹åŠ¨æŒ‡å®š --markdown-dir å‚æ•°")
            return False

    # æ£€æŸ¥æ–‡ä»¶å’Œç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(excel_file):
        print(f"é”™è¯¯: Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")
        return False

    if not os.path.exists(markdown_dir):
        print(f"é”™è¯¯: Markdownç›®å½•ä¸å­˜åœ¨: {markdown_dir}")
        return False

    # è¯»å–Excelæ–‡ä»¶
    try:
        print(f"æ­£åœ¨è¯»å–Excelæ–‡ä»¶: {excel_file}")
        tools = pd.read_excel(excel_file).to_dict('records')
        print(f"å·²åŠ è½½ {len(tools)} æ¡äº§å“æ•°æ®")
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–Excelæ–‡ä»¶: {str(e)}")
        traceback.print_exc()
        return False

    # è·å–æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = glob.glob(os.path.join(markdown_dir, "*.md"))
    if not md_files:
        print(f"é”™è¯¯: åœ¨ {markdown_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½•Markdownæ–‡ä»¶")
        return False

    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")

    # å‡†å¤‡åˆ†æç»“æœ
    analysis_results = []
    for md_file in md_files:
        # ä»æ–‡ä»¶åæå–æ’å
        file_name = os.path.basename(md_file)
        rank_match = re.match(r'^(\d+)-', file_name)
        if not rank_match:
            print(f"è­¦å‘Š: æ— æ³•ä»æ–‡ä»¶åæå–æ’å: {file_name}")
            continue

        rank = int(rank_match.group(1))
        print(f"å¤„ç†æ’å {rank} çš„äº§å“: {file_name}")

        # ä»åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°å¯¹åº”çš„äº§å“
        product = None
        for p in tools:
            p_rank = p.get("Rank") or p.get("æ’å")
            try:
                p_rank = int(p_rank)
            except (ValueError, TypeError):
                continue

            if p_rank == rank:
                product = p
                break

        if not product:
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ’åä¸º {rank} çš„äº§å“æ•°æ®")
            continue

        # ä»æ–‡ä»¶å†…å®¹ä¸­æ£€æµ‹åˆ†æå·¥å…·
        api_name = "DeepSeek AI"  # é»˜è®¤å€¼
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # æ£€æµ‹æ˜¯å¦åŒ…å«OpenAIæˆ–GPT
                if "OpenAI" in content or "GPT" in content:
                    api_name = "OpenAI GPT-4"
                # æ£€æµ‹æ˜¯å¦åŒ…å«DeepSeek
                elif "DeepSeek" in content:
                    api_name = "DeepSeek AI"
                print(f"  æ£€æµ‹åˆ°åˆ†æå·¥å…·: {api_name}")
        except Exception as e:
            print(f"  è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {str(e)}")

        # æ·»åŠ åˆ°åˆ†æç»“æœåˆ—è¡¨
        analysis_results.append({
            "product": product,
            "markdown_path": md_file,
            "api_name": api_name  # æ·»åŠ åˆ†æå·¥å…·ä¿¡æ¯
        })

    if not analysis_results:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœ")
        return False

    print(f"å‡†å¤‡æ›´æ–° {len(analysis_results)} ä¸ªäº§å“çš„åˆ†æç»“æœ")

    # æ›´æ–°Excelæ–‡ä»¶
    try:
        from toolify_utils import update_excel_with_analysis
        updated_file = update_excel_with_analysis(
            excel_file,
            analysis_results,
            markdown_dir=markdown_dir
        )

        if updated_file:
            print(f"æˆåŠŸæ›´æ–°Excelæ–‡ä»¶: {updated_file}")
            return True
        else:
            print("é”™è¯¯: æ›´æ–°Excelæ–‡ä»¶å¤±è´¥")
            return False
    except Exception as e:
        print(f"é”™è¯¯: æ›´æ–°Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®çˆ¬å–ä¸åˆ†æå·¥å…·')
    parser.add_argument('--scraping', dest='do_scraping',
                        action='store_true',
                        help='æ‰§è¡Œæ•°æ®çˆ¬å–æ­¥éª¤')
    parser.add_argument('--scrape', dest='scrape_lang',
                        choices=['cn', 'en', 'both'],
                        default='both',
                        help='çˆ¬å–æ¦œå•çš„è¯­è¨€(cn=ä¸­æ–‡, en=è‹±æ–‡, both=ä¸¤è€…)')
    parser.add_argument('--analysis', dest='do_analysis',
                        action='store_true',
                        help='æ‰§è¡Œæ•°æ®åˆ†ææ­¥éª¤')
    parser.add_argument('--analyze-products', dest='analyze_products',
                        action='store_true',
                        help='åˆ†æäº§å“æ•°æ®')
    parser.add_argument('--gpu', dest='use_gpu',
                        action='store_true',
                        help='ä½¿ç”¨GPUè¿›è¡Œåˆ†æ')
    parser.add_argument('--output-dir', dest='output_dir',
                        default='output',
                        help='åˆ†æç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--batch-size', dest='batch_size',
                        type=int, default=10,
                        help='æ¯æ‰¹å¤„ç†çš„æ•°æ®é‡')
    parser.add_argument('-c', '--count', dest='count',
                        type=int, default=None,
                        help='è¦åˆ†æçš„äº§å“æ•°é‡')
    parser.add_argument('-l', '--language', dest='language',
                        choices=['cn', 'en', 'both'],
                        default='both',
                        help='çˆ¬å–çš„è¯­è¨€(cn=ä¸­æ–‡, en=è‹±æ–‡, both=ä¸¤è€…)')
    parser.add_argument('--rank-range', dest='rank_range',
                        type=str, default=None,
                        help='åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“ï¼Œå¦‚"1-5"')
    parser.add_argument('--api', dest='api',
                        choices=['deepseek', 'openai'],
                        default='deepseek',
                        help='ä½¿ç”¨çš„APIï¼Œé»˜è®¤ä¸ºdeepseek')
    parser.add_argument('--update-excel', dest='update_excel',
                        action='store_true',
                        help='å°†åˆ†æç»“æœæ’å…¥åˆ°Excelè¡¨æ ¼ä¸­')
    parser.add_argument('--retry', dest='retry_count',
                        type=int, default=3,
                        help='APIè°ƒç”¨å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º3æ¬¡')
    parser.add_argument('--insert-md', dest='insert_md',
                        action='store_true',
                        help='ä»…å°†å·²æœ‰çš„MDæ–‡ä»¶å†…å®¹æ’å…¥åˆ°Excelè¡¨æ ¼ä¸­ï¼Œä¸è¿›è¡Œæ–°çš„åˆ†æ')
    parser.add_argument('--excel-file', dest='excel_file',
                        help='Excelæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾')
    parser.add_argument('--markdown-dir', dest='markdown_dir',
                        help='Markdownæ–‡ä»¶ç›®å½•ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾')
    parser.add_argument('--date', dest='date',
                        help='æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYYMMDDï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ')
    parser.add_argument('--no-scraping', dest='no_scraping',
                        action='store_true',
                        help='ä¸ä½¿ç”¨çˆ¬è™«ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°Excelæ–‡ä»¶è¿›è¡Œåˆ†æ')

    # è§£æå‚æ•°
    args = parser.parse_args()

    # è®¾ç½®æ—¥æœŸå­—ç¬¦ä¸²
    date_str = args.date or datetime.now().strftime("%Y%m%d")

    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if args.use_gpu and not GPU_AVAILABLE:
        print("âš ï¸ GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    # å¦‚æœä»…æ’å…¥MDæ–‡ä»¶å†…å®¹åˆ°Excelè¡¨æ ¼ä¸­
    if args.insert_md:
        print(f"\nğŸ” å°†MDæ–‡ä»¶å†…å®¹æ’å…¥åˆ°Excelè¡¨æ ¼ä¸­")

        # ç¡®å®šè¯­è¨€
        if args.language == 'both':
            languages = ["cn", "en"]
        else:
            languages = [args.language]

        # ç¡®å®šæ—¥æœŸå­—ç¬¦ä¸²
        date_str = args.date or datetime.now().strftime("%Y%m%d")

        for lang in languages:
            print(f"\nğŸ” å¼€å§‹å¤„ç†{lang.upper()}è¯­è¨€çš„MDæ–‡ä»¶")

            # æ’å…¥MDæ–‡ä»¶å†…å®¹åˆ°Excelè¡¨æ ¼ä¸­
            success = insert_md_to_excel(
                excel_file=args.excel_file,
                markdown_dir=args.markdown_dir,
                date_str=date_str,
                language=lang
            )

            if success:
                print("âœ… æˆåŠŸå°†MDæ–‡ä»¶å†…å®¹æ’å…¥åˆ°Excelè¡¨æ ¼ä¸­")
            else:
                print("âŒ æ’å…¥MDæ–‡ä»¶å†…å®¹å¤±è´¥")

        print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
        return

    # åˆå§‹åŒ–ç»“æœ
    scraping_results = None
    analysis_result = None
    data_files = {}

    try:
        # æ­¥éª¤1: æ•°æ®çˆ¬å–
        if args.do_scraping:
            print("\nğŸ” æ­¥éª¤1: çˆ¬å–Toolifyæ•°æ®")
            # ç¡®ä¿çˆ¬è™«æ•°æ®ä¿å­˜åˆ°toolify_dataå­ç›®å½•
            scraping_dir = os.path.join(args.output_dir, "toolify_data")

            # æ ¹æ®ç”¨æˆ·é€‰æ‹©è®¾ç½®è¯­è¨€
            if args.language == 'both':
                languages = ["cn", "en"]
            else:
                languages = [args.language]

            # æ‰§è¡Œçˆ¬å–æ“ä½œ
            scraping_results = run_scraping(output_dir=scraping_dir, languages=languages)

            # æå–æ–‡ä»¶è·¯å¾„
            if scraping_results:
                for lang, result in scraping_results.items():
                    if "file" in result:
                        data_files[lang] = result["file"]
        else:
            print("\nğŸ” å·²è·³è¿‡æ•°æ®çˆ¬å–æ­¥éª¤")

            # å¦‚æœè·³è¿‡çˆ¬å–ï¼Œå°è¯•æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶
            data_dir = os.path.join(args.output_dir, "toolify_data")
            latest_files = find_latest_files(data_dir, "Toolify_AI_Revenue_*.xlsx")
            if latest_files:
                data_files = latest_files
                print(f"âœ… æ‰¾åˆ°ä»¥ä¸‹æ•°æ®æ–‡ä»¶:")
                for lang, file_path in data_files.items():
                    print(f"  â€¢ {lang.upper()}: {file_path}")

        # æ­¥éª¤2: æ•°æ®åˆ†æ
        if args.do_analysis:
            print("\nğŸ” æ­¥éª¤2: åˆ†æToolifyæ•°æ®")
            analysis_result = run_analysis(
                scraping_results=scraping_results,
                output_dir=args.output_dir,
                date_str=date_str
            )

            if analysis_result:
                print("âœ… æ•°æ®åˆ†æå®Œæˆ")
            else:
                print("âš ï¸ æ•°æ®åˆ†ææœªå®Œæˆæˆ–æœªè¿”å›ç»“æœ")
        else:
            print("\nğŸ” å·²è·³è¿‡æ•°æ®åˆ†ææ­¥éª¤")

        # æ­¥éª¤3: äº§å“åˆ†æï¼ˆå¯é€‰ï¼‰
        if args.analyze_products:
            print("\nğŸ” æ­¥éª¤3: åˆ†æäº§å“è¯¦æƒ…")

            if not data_files:
                print("âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œäº§å“åˆ†æ")
            else:
                success = run_product_analyzer(
                    data_files=data_files,
                    output_dir=f"output/toolify_analysis_{date_str}",
                    batch_size=args.batch_size,
                    use_gpu=args.use_gpu and GPU_AVAILABLE,
                    count=args.count
                )

                if success:
                    print("âœ… äº§å“åˆ†æå®Œæˆ")
                else:
                    print("âš ï¸ äº§å“åˆ†ææœªå®Œå…¨æˆåŠŸ")

        # æ­¥éª¤4: åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“ï¼ˆå¯é€‰ï¼‰
        if args.rank_range:
            print("\nğŸ” æ­¥éª¤4: åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“")

            # å¤„ç†languageå‚æ•°
            if args.language == 'both':
                # å¦‚æœæŒ‡å®šäº†æ’åèŒƒå›´ä½†languageæ˜¯bothï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡
                print("æ³¨æ„: ä½¿ç”¨--rank-rangeæ—¶ï¼Œå°†é»˜è®¤ä½¿ç”¨ä¸­æ–‡æ•°æ® (cn)")
                lang = "cn"
            else:
                lang = args.language

            # è®¾ç½®è¾“å‡ºç›®å½•
            output_dir_with_date = os.path.join(args.output_dir, f"toolify_analysis_{date_str}")
            os.makedirs(output_dir_with_date, exist_ok=True)

            # å¦‚æœæŒ‡å®šäº†Excelæ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            if args.excel_file and os.path.exists(args.excel_file):
                excel_file = args.excel_file
                print(f"\nğŸ” ä½¿ç”¨æŒ‡å®šçš„Excelæ–‡ä»¶: {excel_file}")
                try:
                    # è¯»å–æ•°æ®
                    tools = pd.read_excel(excel_file).to_dict('records')
                    print(f"âœ… æˆåŠŸè¯»å– {len(tools)} æ¡æ•°æ®")
                except Exception as e:
                    print(f"âš ï¸ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    traceback.print_exc()
                    tools = None
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶è·¯å¾„ä½†è®¾ç½®äº†no_scrapingï¼Œå°è¯•æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶
            elif args.no_scraping:
                # å°è¯•æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶
                excel_file = os.path.join("output", "toolify_data", f"Toolify_AI_Revenue_{lang.upper()}_{date_str}.xlsx")
                if not os.path.exists(excel_file):
                    # å°è¯•å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
                    alt_excel_file = os.path.join("output", "toolify_data", f"Toolify_Top_AI_Revenue_Rankings_{lang.upper()}_{date_str}.xlsx")
                    if os.path.exists(alt_excel_file):
                        excel_file = alt_excel_file
                    else:
                        # å°è¯•æŸ¥æ‰¾ä»»ä½•åŒ¹é…çš„Excelæ–‡ä»¶
                        excel_files = glob.glob(os.path.join("output", "toolify_data", f"*{lang.upper()}*{date_str}*.xlsx"))
                        if excel_files:
                            excel_file = excel_files[0]
                        else:
                            print(f"âš ï¸ æ‰¾ä¸åˆ°æœ¬åœ°Excelæ–‡ä»¶ï¼Œè¯·æŒ‡å®š --excel-file å‚æ•°")
                            return

                print(f"\nğŸ” ä½¿ç”¨æœ¬åœ°Excelæ–‡ä»¶: {excel_file}")
                try:
                    # è¯»å–æ•°æ®
                    tools = pd.read_excel(excel_file).to_dict('records')
                    print(f"âœ… æˆåŠŸè¯»å– {len(tools)} æ¡æ•°æ®")
                except Exception as e:
                    print(f"âš ï¸ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                    traceback.print_exc()
                    tools = None
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶è·¯å¾„ä¸”æ²¡æœ‰è®¾ç½®no_scrapingï¼Œä½¿ç”¨çˆ¬è™«
            else:
                # å…ˆè°ƒç”¨toolify_scraper.pyä¸­çš„mainå‡½æ•°çˆ¬å–æœ€æ–°çš„æ¦œå•æ•°æ®
                print("\nğŸ” æ­£åœ¨è°ƒç”¨toolify_scraper.pyä¸­çš„mainå‡½æ•°çˆ¬å–æœ€æ–°çš„æ¦œå•æ•°æ®...")
                try:
                    scrape_main()
                    print("âœ… çˆ¬å–å®Œæˆ")

                    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
                    excel_file = os.path.join("output", "toolify_data", f"Toolify_AI_Revenue_{lang.upper()}_{date_str}.xlsx")

                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if os.path.exists(excel_file):
                        # è¯»å–æ•°æ®
                        tools = pd.read_excel(excel_file).to_dict('records')
                    else:
                        tools = None
                        print(f"âš ï¸ æ‰¾ä¸åˆ°æ–‡ä»¶: {excel_file}")
                except Exception as e:
                    print(f"âš ï¸ çˆ¬å–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    traceback.print_exc()
                    tools = None
                    excel_file = None

            if not tools or not excel_file:
                print("âš ï¸ è·å–æ¦œå•æ•°æ®å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            else:
                if args.no_scraping:
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(tools)} ä¸ªäº§å“æ•°æ®")
                else:
                    print(f"âœ… æˆåŠŸçˆ¬å– {len(tools)} ä¸ªäº§å“æ•°æ®")

                # åˆ†ææŒ‡å®šæ’åèŒƒå›´çš„äº§å“
                success = analyze_specific_ranks(
                    args.rank_range,
                    lang,
                    date_str,
                    api=args.api,
                    use_gpu=args.use_gpu,
                    update_excel=args.update_excel,
                    retry_count=args.retry_count
                )

                if success:
                    print("âœ… æŒ‡å®šæ’åèŒƒå›´çš„äº§å“åˆ†æå®Œæˆ")
                else:
                    print("âš ï¸ æŒ‡å®šæ’åèŒƒå›´çš„äº§å“åˆ†ææœªå®Œæˆæˆ–æœªè¿”å›ç»“æœ")

        print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


